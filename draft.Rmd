---
title: "project"
author: "Bogdan Abaev"
date: "4/10/2020"
output: html_document
---

```{r}
library(caret)
library(rpart)
require(mosaic)
require(gtools)
require(rpart.plot)
```

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
fights = read.csv("/Users/bogdanabaev/College/MAT336/project/ufcdata/data.csv")
fighters = read.csv("/Users/bogdanabaev/College/MAT336/project/ufcdata/raw_fighter_details.csv")
ufc3 = na.omit(fights)
ufc3$Red_Won = ufc3$Winner == "Red"

set.seed(410)
train_ind <- sort(sample(nrow(ufc3), nrow(ufc3)*0.8))

train <- ufc3[train_ind,]
test <- ufc3[-train_ind,]
```


Now that we have variables worthy of looking at, we will try to find the best model.

```{r}
fit <- rpart(as.formula(paste("Winner", "~", paste(colnames(train)[c(8:145)], collapse = "+"),sep ="")),
   method="class", data=train)

printcp(fit) 
plotcp(fit) 
summary(fit) 

rpart.plot(fit, box.palette = list("lightblue", "pink"))

```


```{r}
candidates_from_tree = c("B_avg_BODY_att", "B_avg_opp_CLINCH_att","R_age","R_avg_GROUND_att", "R_avg_opp_SIG_STR_landed")

candidates_from_background = c("B_current_win_streak","R_current_win_streak","B_avg_BODY_landed","R_avg_BODY_landed",
"B_total_rounds_fought","R_total_rounds_fought","B_Reach_cms","R_Reach_cms")

candidates = c(candidates_from_background, candidates_from_tree)
```

```{r}
worthy = c()
for(i in 1:length(candidates)){
  var = candidates[i]
  if(is.numeric(train[,var])){
    model = glm(Red_Won ~ train[,var], data=train,family=binomial(link = "logit"))
    p = summary(model)$coefficients[8]
    if (!is.na(p) && p < 0.05){
      worthy[i] = var
    }
  }
}
worthy = worthy[!is.na(worthy)]
worthy
```



```{r, include=TRUE, echo=TRUE}
# combinations of different sizes
one = combinations(9,1,v=worthy)
two = combinations(9,2,v=worthy)
three = combinations(9,3,v=worthy)
four = combinations(9,4,v=worthy)
five = combinations(9,5,v=worthy)
six = combinations(9,6,v=worthy)
seven = combinations(9,7,v=worthy)
eight = combinations(9,8,v=worthy)
nine = combinations(9,9,v=worthy)

check_combs = function(groups){
  n = length(groups[,1])
  explained_max = 0
  best_model = c()
  for(i in c(1:n)){
    var_names = groups[i,]
    model = glm(as.formula(paste("Red_Won", "~", paste(var_names, collapse = "+"),sep ="")) , data = train, family=binomial(link = "logit"))
    ps = summary(model)[4]$coefficients[,4]
    predictions = predict(model, train)
    predictions = predictions > 0.5
    expected = train$Red_Won
    explained = sum(predictions == expected)
    if (all(ps < 0.05) &&explained > explained_max){
      best_model = var_names
      explained_max = explained
    }
  }
  c(best_model, explained_max)
}
one_result= check_combs(one)
two_result = check_combs(two)
three_result = check_combs(three) # best one!
four_result = check_combs(four)
five_result = check_combs(five) 
six_result = check_combs(six)
seven_result = check_combs(seven)
eight_result = check_combs(eight)
nine_result = check_combs(nine)
```


```{r, echo=TRUE}
main_test = function(results, number){
  best_model = results[c(1:number)]
  model = glm(as.formula(paste("Red_Won", "~", paste(best_model, collapse = "+"),sep ="")) , data = train, family=binomial(link = "logit"))
  predictions = predict(model, test)
  predictions = predictions > 0.5
  expected = test$Red_Won
  explained = sum(predictions == expected)
  explained 
}
```

```{r}
main_test(one_result,1) 
main_test(two_result,2) 
main_test(three_result,3) 
main_test(four_result ,4)
main_test(five_result  ,5)
main_test(six_result ,6)
main_test(seven_result,7) 
main_test(eight_result,8)
main_test(nine_result ,9)
```
